### Reflektioner laboration 1 
1. Vad tror Du vi har för skäl till att spara det skrapade datat i JSON-format?
>######För att det ska vara lagras i ett standardiserat format, som är lätt att läsa och skriva.
2. Olika jämförelsesiter är flitiga användare av webbskrapor. Kan du komma på fler typer av tillämplingar där webbskrapor förekommer?
>######Journalistik, tidningar. Finansiella verksamheter.
3. Hur har du i din skrapning underlättat för serverägaren?
>######En skrapning körs maximalt var 5:e minut
4. Vilka etiska aspekter bör man fundera kring vid webbskrapning?
>######Jag uppfattar det som att det är syftet med skrapningen som avgör huruvida det är etiskt eller ej.
5. Vad finns det för risker med applikationer som innefattar automatisk skrapning av webbsidor? Nämn minst ett par stycken!
>######Kvaliteten på skrapan är viktig, så att skrapningen inte blir en DDoS-attack. 
>######Om sajten som man skrapar förändras, så är det ju stor risk att den skrapa man skrivit inte fungerar längre.
6. Tänk dig att du skulle skrapa en sida gjord i ASP.NET WebForms. Vad för extra problem skulle man kunna få då?
>######Viewstate.
7. Välj ut två punkter kring din kod du tycker är värd att diskutera vid redovisningen. Det kan röra val du gjort, tekniska lösningar eller lösningar du inte är riktigt nöjd med.
>######Det kanske hade fungerat bättre om jag sparat ner strängarna som jag fått från curl lokalt eller kört funktionen som hämtar flera filer på samma gång.
>######Det är svårt att förutse hur lösningen kommer att fungera när man ökar mängden data. 
>######Vilka alternativ finns det för att lösa det på? 
>######Vilket är bäst? 
>######Hur tänka på bästa sätt för att hitta lösningar?
8. Hitta ett rättsfall som handlar om webbskrapning. Redogör kort för detta.
>######I fallet Feist Publications v. Rural Telephone Service beslutade domstolen (i USA) att duplicering av fakta är ok. Att regelrätt kopiera hela webbplatser är i de flesta fall olagligt.
9. Känner du att du lärt dig något av denna uppgift?
>######Absolut.
